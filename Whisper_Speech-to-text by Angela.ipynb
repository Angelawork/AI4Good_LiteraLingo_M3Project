{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEhX9CfIRKSKDh/N3Z3i5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelawork/AI4Good_LiteraLingo_M3Project/blob/main/Whisper_Speech-to-text%20by%20Angela.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial https://medium.com/gimz/how-to-use-whisper-a-speech-recognition-model-that-turns-audio-into-text-a10bf182d85b\n",
        "## involve translation: https://www.assemblyai.com/blog/how-to-run-openais-whisper-speech-recognition-model/"
      ],
      "metadata": {
        "id": "n8M8YVoADMvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F75B8U8uAxqa"
      },
      "outputs": [],
      "source": [
        "# install openai's whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# update the packages\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing by youtube"
      ],
      "metadata": {
        "id": "VNrPZX_2EWJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vVZ8eE3EhNZ",
        "outputId": "42a95c58-da7f-476e-ca3b-bc0a9c257ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 86.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "import pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLmquv1uEYMU",
        "outputId": "1ad47563-a35c-4fa0-d6eb-e397f990af68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = \"https://www.youtube.com/watch?v=JhU0yO43b6o\"\n",
        "data = pytube.YouTube(video)\n",
        "# Converting and downloading as 'MP4' file\n",
        "audio = data.streams.get_audio_only()\n",
        "audio.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uuul5T1bEcOJ",
        "outputId": "fc788288-31f9-42dd-d307-9395f542727e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Sample Video To Practice Transcribing.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transcript from Youtube:\n",
        "\n",
        "## hey there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on youtube. alls i'm looking for you to do here is to use the youtube tool to transcribe this message, and then click sync and set the timing, so you can get a quick idea about how the whole process works. well this wraps up the video, good luck, and i will talk to you about it soon.\n"
      ],
      "metadata": {
        "id": "y5WDNCr6GR2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.transcribe(\"/content/Sample Video To Practice Transcribing.mp4\",language='en')\n",
        "out['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "a520YkgQExeV",
        "outputId": "cadbe4b5-c01a-4aa0-cfe1-2ffe2ccf5a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hey there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. All I'm looking for you to do here is to use the YouTube tool to transcribe this message and then click sync and set the timing so you can get a quick idea about how the whole process works. Well, this wraps up the video. Good luck and I will talk to you about it soon.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. All I'm looking for you to do here is to use the YouTube tool to transcribe this message and then click sync and set the timing so you can get a quick idea about how the whole process works. Well, this wraps up the video. Good luck and I will talk to you about it soon."
      ],
      "metadata": {
        "id": "Un6T3BL9Bdgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try tiny model"
      ],
      "metadata": {
        "id": "enaIU9q6GE7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tiny Whisper model\n",
        "model2 = whisper.load_model(\"tiny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKXc4TQLGEmk",
        "outputId": "81134e70-a68d-4afd-c1ca-90bc15cd0614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 69.1MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model2.transcribe(\"/content/Sample Video To Practice Transcribing.mp4\",language='en')\n",
        "out['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "TCqxAToAGG_m",
        "outputId": "74e58e76-80b0-49dc-a1c8-384c13c3237d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Here there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. Also looking for you to do here is to use the YouTube tool to transcribe this message and then click sync and set the time and so you can get a quick idea about how the whole process works. Well, this wraps up the video, good luck, and I will talk to you about it soon.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Here there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. Also looking for you to do here is to use the YouTube tool to transcribe this message and then click sync and set the time and so you can get a quick idea about how the whole process works. Well, this wraps up the video, good luck, and I will talk to you about it soon."
      ],
      "metadata": {
        "id": "eUWesVK2Bi4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try a longer video 6:08"
      ],
      "metadata": {
        "id": "UDzb5og5HhFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = \"https://www.youtube.com/watch?v=MUEHb4jWclA\"\n",
        "data = pytube.YouTube(video)\n",
        "# Converting and downloading as 'MP4' file\n",
        "audio = data.streams.get_audio_only()\n",
        "audio.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iF69Ylm3HssF",
        "outputId": "e14d3c92-e2e1-4491-d1d3-30322a47deba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ABC PODCAST WITH TRANSCRIPT.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference=\"/content/test.txt\""
      ],
      "metadata": {
        "id": "VgcKOX1bIkPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.transcribe(\"/content/ABC PODCAST WITH TRANSCRIPT.mp4\",language='en')\n",
        "out['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "9GIHPrSpIHKk",
        "outputId": "1a8bd42d-c00d-45c5-ab5b-d18183742ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Two specialists writing in the Medical Journal of Australia last week described a disease that they claim has increased exponentially in the last 20 years and which can be confused for commoner garden indigestion and acid reflux. It's called eosinophilic oesophagitis and it could be you if you have reflux which isn't being helped by the usual acid-reducing treatments. One of the authors was Associate Professor Peter Katilaris who heads the Gastroenterology Department at Concord Hospital in Sydney. Welcome to the Health Report Peter. Thanks Norman, nice to be here. What's the common story that you get from someone who might have eosinophilic oesophagitis? The common story is a person who has difficulty in swallowing. We call that dysphagia when the food either doesn't go down easily and needs to be helped along or brought back up or in fact gets stuck. So people with this problem who don't have it recognised often live with that sort of symptom for a long time before it's appropriately diagnosed. And what about the symptoms of reflux itself? Well that's interesting. Eosinophilic oesophagitis is a great mimicker and it can mimic typical common refluxes as you mentioned. So people can have heartburn and regurgitation and chest pain. Normally people with reflux don't get too much of that dysphagia but they can get that as well. So really it requires a medical evaluation to distinguish the two and to make it more complex they do overlap. In other words reflux is really very common as a condition and eosinophilic oesophagitis is becoming more common so they often coexist. So while one's a mimic of the other they also coexist. So it really needs to be sorted out medically and that's not so difficult to do once it's thought about. But you talk in the paper about how this is under diagnosed but difficulty swallowing is a red light for any doctor seeing a patient. Well it sure is especially if it happens in someone after a certain age and it's a new onset symptom. But people with this problem often have a long history of just saying every now and then something gets stuck or they're always the last to finish their dinner or they're chewing very slowly and they're just managing it. So it's less of a red flag if it's been present for years but it's certainly a red flag for something very serious if it's just occurred. So what's actually going on? So what's happening is we think this is an allergic problem and we think the trigger is usually something people eat. So it's usually related to some food substance although there's a theory that it might also be an inhaled substance what we call an aeroallergen. But mostly we think it's a reaction. So it's like a gastroenterological version of asthma. Yeah it is in a way because withdrawing agents that are known to offend to trigger this can be a treatment although not as good as medical therapy. And what happens when people are exposed if they're susceptible and it is normally people who have ATP of some sort hay fever or asthma is that their esophagus or food pipe gets infiltrated by allergy cells. That's the eosinophils in the name of the disease. And that alters the way the esophagus works so that food doesn't go down easily. The esophagus's motility is altered. So do you have to have an endoscopy to diagnose it? Yes there's no other way. It can be suspected just on symptoms but you really do have to have an endoscopy and the endoscopist has to be aware of the condition and not just look but also take biopsies along the esophagus and it's the characteristic pathology on the biopsies that gives the diagnosis So how do you know what the cause might be or is that too hard? Well it always is too hard but I guess the best evidence relates to what happens when we exclude certain foods from people's diet and some people get better and then if they're re-challenged they can relapse. And that makes us think that in most people it is an allergic response to certain foods. The trouble is there's a lot of foods that can trigger it and it's very hard to exclude those foods long term and that's why medical treatment is preferred over long term dietary exclusions. Does it predispose to cancer in the same way as, well it's controversial but acid reflux is thought to predispose to cancer? Fortunately no it doesn't. Reflux certainly does predispose to cancer but the overall risk is very small but EOE as we call it is not thought to share that predisposition. The real issue is that it greatly affects people's quality of life because they're scared to eat or can't have certain foods and there's the danger of food impaction which can be quite dangerous. And if it's left untreated the esophagus can stiffen and narrow so there's now a structural chronic problem that needs endoscopic dilatations to improve it. So it's not a trivial illness and it certainly has been under-recognised up until recently. And so in other words the increase is probably along with the general increase in allergies in the community. How do you treat it? Well the treatment is one of two options. We've mentioned food exclusion but only a small minority of people are willing or able to persevere with that and the results are moderate rather than good. The mainstay of treatment is taking a type of topical steroid that's not absorbed into the whole body so there's very very few side effects and it's like a topical therapy because steroids make eosinophils melt away and that type of treatment is very effective. So this is like the inhaled cortical steroids that you take to prevent asthma? It's interesting you mention that because up until very recently we actually had to repurpose asthma treatments because there wasn't a purpose-designed way of getting that exact same medicine into the esophagus. So we used to teach patients how to have a bad asthma technique with their puffers to get it into their esophagus. So swallowing the puffer rather than inhaling it? Yeah but now there's just recently been the development of an oral dispersable form of that medicine which is so much easier for patients to take. So they just put a little tablet on the tongue and it dissolves and that goes down to the right place without any repurposing of asthma medication. So for a health report, listen, we think we might have this have a chat with your GP and get an endoscopy. Oh very much so. It's a tolerably easy diagnosis once it's considered. Then the management is long term but the diagnosis is not difficult if it's thought about. Peter, thanks for joining us. It's a pleasure. Associate Professor Peter Kartilaris is head of the gastroenterology department at Concord Hospital in Sydney.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate\n",
        "\n",
        "The resulting value ranges between -1 and 1, where 1 indicates that the vectors are identical, 0 indicates no similarity, and -1 indicates complete dissimilarity or opposite directions."
      ],
      "metadata": {
        "id": "7NpeISeVJxp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sEcTjXCKjVa",
        "outputId": "a99b341a-4eaa-44c6-9019-c50d3c04c334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEZbGq0VP-32",
        "outputId": "3200daf9-870e-4b4d-f262-2f53529eb4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Preprocessing\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    # Remove stop words and punctuation\n",
        "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    # Return the preprocessed text as a string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    # Preprocess the texts\n",
        "    preprocessed_text1 = preprocess_text(text1)\n",
        "    preprocessed_text2 = preprocess_text(text2)\n",
        "\n",
        "    # Vectorize the texts\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([preprocessed_text1, preprocessed_text2])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
        "    similarity_score = similarity_matrix[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Specify the path to the text file\n",
        "file_path = reference\n",
        "\n",
        "# Read the file contents\n",
        "with open(file_path, 'r') as file:\n",
        "    script = file.read()\n",
        "\n",
        "similarity = calculate_cosine_similarity(script, out['text'])\n",
        "print(f\"Cosine Similarity: {similarity}\")"
      ],
      "metadata": {
        "id": "RWImf2chI0LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity: 0.9422014983399177"
      ],
      "metadata": {
        "id": "T7gn5b4HQDDC"
      }
    }
  ]
}